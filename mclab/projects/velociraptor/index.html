<html>
<title> Velociraptor: Toolkit for building compilers for GPUs</title>
<body>
<img src="header.jpg" width="100%">
<style type="text/css">
.vrcentre {
  margin-left:20%;
  margin-right:20%;
  font-family:"verdana";
  font-size:18;
}
</style>
<div class="vrcentre">
<br>
<br>
Are you building a compiler for array-based languages, targeting CPUs and GPUs? Then you will be interested in the tools we are building.
Our tools will make it easier for you to quickly build your compiler. Our tools work across hardware vendors, and (soon) will be open-source under a very liberal license.
<p>
These tools are being built by Rahul Garg as part of his ongoing PhD. thesis about compiling array-based languages to hybrid CPU/GPU systems. 
The project is being supervised <a href="http://www.sable.mcgill.ca/~hendren">Prof. Laurie Hendren</a> at <a href="http://www.sable.mcgill.ca">SABLE lab</a> and 
is part of the <a href="http://www.sable.mcgill.ca/mclab">McLab</a> project. 
</p>

<p>
Are you a compiler writer or a hardware vendor? We will be very interested in hearing from you! You can contact Rahul by emailing him at his firstname.lastname@mail.mcgill.ca
</p>

<h2>Velociraptor</h2>

Velociraptor is a compiler toolkit consisting of a code generation library as well as a runtime system. It takes as input a high-level IR called Velociraptor IR (VRIR for short) that is designed to accomodate array semantics of many different languages. VRIR is a typed AST based representation that is easy to generate, and has built-in operators for many high-level array operations (like matrix multiplication), flexible array indexing schemes, and array layouts. Velociraptor generates LLVM for CPUs and OpenCL for GPUs, making it portable across many different systems.
Velociraptor is accompanied by its intelligent runtime system, that is designed for maximizing throughput in hybrid systems by doing operations in parallel and by minimizing redundant data transfers.

<p>
Velociraptor has it's own high-level IR called VRIR that is easy to generate from array-based languages and includes 
high-level constructs for parallelism and GPU acceleration. VRIR has a textual representation inspired from Lisp S-expressions.
A high-level overview for VRIR can be found <a href="http://www.raijincl.org/vrir.pdf">here</a>. 
The grammar for VRIR textual representation can be found <a href="http://www.raijincl.org/Vrir.g">here </a>.
</p>

<h2>RaijinCL</h2>

RaijinCL is a high-performance, portable libary for implementing many matrix operations on the GPU such as matrix multiplication and reductions. It is difficult to write a single OpenCL code that works well everywhere. Therefore, RaijinCL does autotuning, a process where it tests hundreds of different versions of important functions and records the best one found on a user's machine. Initial results are encouraging, and we are able to match the performance of vendor libraries on some systems, and deliver good performance everywhere. 

RaijinCL currently consists of GEMM-inspired (GEMM = general matrix multiply) routines, reduction routines for calulating sum and product of elements of multidimensional arrays along a particular axis as well as several element-wise operations on strided multidimensional arrays. We are also looking into more routines such as matrix decomposition.

<h2>MATLAB and Python compilers</h2>

We are demonstrating the use of our tools above by using the tools in two different projects. First, we are using it to enable the use of GPUs in <a href="http://www.sable.mcgill.ca/mclab/mcvm_mcjit.html">McVM</a>, 
a virtual machine for MATLAB language built at our lab. 
Second, we have a proof-of-concept system for compiling annotataed Python code (specifically the numerical subset using NumPy) where both CPU and GPU code generation is handled by Velociraptor.
These will also be open-sourced and will be useful for any user of these languages, not only compiler writers.

<h2>Publications and Presentations</h2>
<ul>
<li> "Velociraptor: an embedded compiler toolkit for numerical programs targeting CPUs and GPUs" by Rahul Garg, Laurie Hendren at <a href="http://dl.acm.org/citation.cfm?id=2628071.2628097">PACT 2014</a> </li>
<li> "Just-in-time shape inference for array languages" by Rahul Garg, Laurie Hendren at <a href="http://dl.acm.org/citation.cfm?id=2627373.2627382"> ARRAY 14 </a></li>
<li> "A Portable and High-Performance General Matrix-Multiply (GEMM) Library for GPUs and Single-Chip CPU/GPU Systems." by Rahul Garg, Laurie Hendren at PDP 2014 </li>
<li>Presentation: CASCON Compiler Driven Performance workshop 2012: <a href="cdp12.pdf">PDF</a> (presentation only, workshop does not have proceedings)</li>
</ul>
<h2>Software</h2>
RaijinCL download and support can be found <a href="http://www.raijincl.org">here</a><br>
Velociraptor downloads coming soon. Private builds are available, please contact me by email. <br>
</div>
</body>
</html>
